{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f73235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.addmul import HandleAddMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1725af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d525037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n"
     ]
    }
   ],
   "source": [
    "network_cache_dir = \"networks/cache-networks/\"\n",
    "network_name = \"lyr256-split0.8-lr0.01-add-mul.data\"\n",
    "\n",
    "checkpoint = True\n",
    "test_flag = 1\n",
    "\n",
    "input_dims = [42]\n",
    "output_dims = [20]\n",
    "batchsize = 128\n",
    "num_epochs = 1\n",
    "\n",
    "handler = HandleAddMul(input_dims, output_dims, dir=network_cache_dir + network_name, checkpoint=checkpoint, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d6cd4",
   "metadata": {},
   "source": [
    "## generate mask on addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d068d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "for layer in handler.network.layers[0]:\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        logits.append(torch.full_like(layer.weight.data, 0.9, requires_grad=True))\n",
    "\n",
    "logits_generator = iter(logits)\n",
    "        \n",
    "for name, param in handler.network.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "\n",
    "data_fp = \"generate_datasets/tmp/digit-data/simple_add.npy\"\n",
    "data = np.load(data_fp, allow_pickle=True)\n",
    "\n",
    "data_len = len(data)\n",
    "train_split_idx = int(data_len * train_split)\n",
    "train_data = data[:train_split_idx]\n",
    "test_data = data[train_split_idx:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.tensor(train_data), batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.Tensor(test_data), batch_size=batchsize, shuffle=True)\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "iterator_train = iter(cycle(train_loader))\n",
    "iterator_test = iter(cycle(test_loader))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(logits, lr=0.01)\n",
    "\n",
    "NUM_EPOCHS = 20000  # NB: check for number of training epochs in paper\n",
    "tau = 1  # temperature parameter, NB: check for value in paper\n",
    "alpha = 0.0001/128  # regularisation parameter, NB: check for value in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7870268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 1...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 2...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 3...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 4...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 5...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 6...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 7...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 8...\n",
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Load saves ...\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Starting epoch 9...\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "loss_hist = []\n",
    "avg = []\n",
    "NUM_EPOCHS = 20000\n",
    "\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(f'Starting epoch {e}...')\n",
    "    \n",
    "    '''Reload weights'''\n",
    "    handler = HandleAddMul(input_dims, output_dims, dir=network_cache_dir + network_name, checkpoint=checkpoint, lr=0.001)\n",
    "    \n",
    "    '''Sampling and generating masks.'''\n",
    "\n",
    "    U1 = torch.rand(1, requires_grad=False).to(handler.network.device)\n",
    "    U2 = torch.rand(1, requires_grad=False).to(handler.network.device)\n",
    "    \n",
    "    samples = []\n",
    "\n",
    "    for layer in logits:\n",
    "#         layer.requires_grad_(requires_grad=True)\n",
    "        samples.append(torch.sigmoid((layer - torch.log(torch.log(U1) / torch.log(U2))) / tau))\n",
    "\n",
    "    binaries_stop = []\n",
    "\n",
    "    for layer in samples:\n",
    "        with torch.no_grad():\n",
    "            binaries_stop.append((layer > 0.5).float() - layer)\n",
    "\n",
    "    binaries = []\n",
    "    iterator_samples = iter(samples)\n",
    "\n",
    "    for layer in binaries_stop:\n",
    "        binaries.append(layer + next(iterator_samples))\n",
    "\n",
    "    iterator_binaries = iter(binaries)\n",
    "\n",
    "    for layer in handler.network.layers[0]:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            layer.weight.data * next(iterator_binaries)\n",
    "            print(layer.weight.data.requires_grad)\n",
    "    '''Inference with masked network and backpropagation.'''\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    batch = next(iterator_train)\n",
    "#     with torch.no_grad():\n",
    "    # Load in batch data (not binaries for one-hot input)\n",
    "    inp = torch.stack([torch.stack([b[0], b[1]]) for b in batch])\n",
    "    otp = torch.stack([b[2] for b in batch])\n",
    "    ops = torch.stack([b[3] for b in batch])\n",
    "    # Convert batch data toone-hot representation\n",
    "    inp, otp_ = handler.set_batched_digits(inp, otp, ops)\n",
    "\n",
    "    inp_ = inp.to(handler.network.device)\n",
    "    otp_ = otp_.to(handler.network.device)\n",
    "\n",
    "    otp_pred = handler.network(inp_)\n",
    "    #otp_pred.requires_grad = True\n",
    "\n",
    "        \n",
    "    all_logits = alpha*torch.cat([layer.view(-1) for layer in logits]).to(handler.network.device)\n",
    "    \n",
    "    loss = criterion(otp_pred, otp_).to(handler.network.device) + torch.sum(all_logits).detach()\n",
    "    #loss.requires_grad = True\n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    loss_hist.append(loss.item())\n",
    "    avg.append(np.mean(loss_hist[-100:]))\n",
    "    if e % 100 == 0:\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        #plt.plot(loss_hist)\n",
    "        plt.plot(avg)\n",
    "        plt.savefig('liveplot.png')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    if e % 2000 == 0:\n",
    "        torch.save(logits, 'masks/trained_logits_add_mask.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d9896",
   "metadata": {},
   "source": [
    "## generate mask on multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "\n",
    "data_fp = \"generate_datasets/tmp/digit-data/simple_mul.npy\"\n",
    "data = np.load(data_fp, allow_pickle=True)\n",
    "\n",
    "data_len = len(data)\n",
    "train_split_idx = int(data_len * train_split)\n",
    "train_data = data[:train_split_idx]\n",
    "test_data = data[train_split_idx:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.tensor(train_data), batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.Tensor(test_data), batch_size=batchsize, shuffle=True)\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "iterator_train = iter(cycle(train_loader))\n",
    "iterator_test = iter(cycle(test_loader))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimiser = torch.optim.Adam(logits, lr=0.01)\n",
    "\n",
    "NUM_EPOCHS = 20000  # NB: check for number of training epochs in paper\n",
    "tau = 1  # temperature parameter, NB: check for value in paper\n",
    "alpha = 0.0001/128  # regularisation parameter, NB: check for value in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2509565",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "NUM_EPOCHS = 20000\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(f'Starting epoch {e}...')\n",
    "\n",
    "    '''Sampling and generating masks.'''\n",
    "\n",
    "    U1 = torch.rand(1, requires_grad=True).to(handler.network.device)\n",
    "    U2 = torch.rand(1, requires_grad=True).to(handler.network.device)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for layer in logits:\n",
    "        layer.requires_grad_(requires_grad=True)\n",
    "\n",
    "        #         if layer.grad is not None:\n",
    "        #             layer.grad.detach_()\n",
    "        #             layer.grad.zero_()\n",
    "\n",
    "        samples.append(torch.sigmoid((layer - torch.log(torch.log(U1) / torch.log(U2))) / tau))\n",
    "\n",
    "    binaries_stop = []\n",
    "\n",
    "    for layer in samples:\n",
    "        with torch.no_grad():\n",
    "            binaries_stop.append((layer > 0.5).float() - layer)\n",
    "\n",
    "    binaries = []\n",
    "    iterator_samples = iter(samples)\n",
    "\n",
    "    for layer in binaries_stop:\n",
    "        binaries.append(layer + next(iterator_samples))\n",
    "\n",
    "    iterator_binaries = iter(binaries)\n",
    "\n",
    "    for layer in handler.network.layers[0]:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            layer.weight.data * next(iterator_binaries)\n",
    "\n",
    "    '''Inference with masked network and backpropagation.'''\n",
    "\n",
    "    batch = next(iterator_train)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Load in batch data (not binaries for one-hot input)\n",
    "        inp = torch.stack([torch.stack([b[0], b[1]]) for b in batch])\n",
    "        otp = torch.stack([b[2] for b in batch])\n",
    "        ops = torch.stack([b[3] for b in batch])\n",
    "        # Convert batch data toone-hot representation\n",
    "        inp, otp_ = handler.set_batched_digits(inp, otp, ops)\n",
    "        \n",
    "        inp_ = inp.to(handler.network.device)\n",
    "        otp_ = otp_.to(handler.network.device)\n",
    "        \n",
    "        otp_pred = handler.network(inp_)\n",
    "\n",
    "        \n",
    "    all_logits = alpha*torch.cat([layer.view(-1) for layer in logits]).to(handler.network.device)\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    loss = criterion(otp_pred, otp_).to(handler.network.device) + torch.sum(all_logits)\n",
    "    #loss.requires_grad = True\n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    loss_hist.append(loss.item())\n",
    "    \n",
    "    if e % 200 == 0:\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.plot(loss_hist)\n",
    "        plt.savefig('liveplot.png')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        torch.save(logits, 'masks/trained_logits_mul_mask.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5abc7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
