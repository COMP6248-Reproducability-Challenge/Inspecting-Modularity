{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f73235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.addmul import HandleAddMul\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "network_cache_dir = \"networks/cache-networks/\"\n",
    "network_name = \"lyr256-split0.8-lr0.01-add-mul.data\"\n",
    "\n",
    "checkpoint = True\n",
    "test_flag = 1\n",
    "\n",
    "input_dims = [42]\n",
    "output_dims = [20]\n",
    "batchsize = 128\n",
    "num_epochs = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc2d6092",
   "metadata": {},
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5dd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Data'''\n",
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "data_fp = \"generate_datasets/tmp/digit-data/simple_add.npy\"\n",
    "data = np.load(data_fp, allow_pickle=True)\n",
    "data_len = len(data)\n",
    "train_split_idx = int(data_len * train_split)\n",
    "train_data = data[:train_split_idx]\n",
    "test_data = data[train_split_idx:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.tensor(train_data), batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.Tensor(test_data), batch_size=batchsize, shuffle=True)\n",
    "\n",
    "iterator_train = iter(cycle(train_loader))\n",
    "iterator_test = iter(cycle(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d6cd4",
   "metadata": {},
   "source": [
    "## generate mask on addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7870268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-add-mul.data\n",
      "Starting epoch 0...\n",
      "Accuracy: 0.9 \n",
      "Parameter containing:\n",
      "tensor([[0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000],\n",
      "        ...,\n",
      "        [0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000],\n",
      "        [0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Saving Mask...\n",
      "Starting epoch 1...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 2...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 3...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 4...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 5...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 6...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 7...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 8...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 9...\n",
      "Accuracy: 0.073046875 \n",
      "Starting epoch 10...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 11...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 12...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 13...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 14...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 15...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 16...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 17...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 18...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 19...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 20...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 21...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 22...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 23...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 24...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 25...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 26...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 27...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 28...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 29...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 30...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 31...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 32...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 33...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 34...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 35...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 36...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 37...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 38...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 39...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 40...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 41...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 42...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 43...\n",
      "Accuracy: 0.012109375 \n",
      "Starting epoch 44...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 45...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 46...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 47...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 48...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 49...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 50...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 51...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 52...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 53...\n",
      "Accuracy: 0.712109375 \n",
      "Starting epoch 54...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 55...\n",
      "Accuracy: 0.079296875 \n",
      "Starting epoch 56...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 57...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 58...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 59...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 60...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 61...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 62...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 63...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 64...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 65...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 66...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 67...\n",
      "Accuracy: 0.01953125 \n",
      "Starting epoch 68...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 69...\n",
      "Accuracy: 0.801953125 \n",
      "Starting epoch 70...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 71...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 72...\n",
      "Accuracy: 0.9 \n",
      "Starting epoch 73...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 74...\n",
      "Accuracy: 0.0 \n",
      "Starting epoch 75...\n"
     ]
    }
   ],
   "source": [
    "'''Initialise logits & define loss and Optimiser'''\n",
    "handler = HandleAddMul(input_dims, output_dims, dir=network_cache_dir+network_name, \n",
    "                       checkpoint=checkpoint, use_optimiser=False)\n",
    "handler.refreeze_weights()\n",
    "\n",
    "logits = []\n",
    "for layer in handler.network.layers[0]:\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "        layer.weight.data = layer.weight.detach()\n",
    "        inter = torch.full_like(layer.weight, 0.9)\n",
    "        logits.append(torch.nn.Parameter(inter, requires_grad=True))\n",
    "\n",
    "for l in logits:    \n",
    "    l.requires_grad_(requires_grad=True)\n",
    "    h = l.register_hook(lambda grad: grad)\n",
    "        \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(logits, lr=0.01)\n",
    "\n",
    "'''Initialise hyper-parameters'''\n",
    "NUM_EPOCHS = 20000  # NB: check for number of training epochs in paper\n",
    "tau = 1  # temperature parameter, NB: check for value in paper\n",
    "alpha = 0.0001/128  # regularisation parameter, NB: check for value in paper\n",
    "loss_hist = []\n",
    "avg = []\n",
    "\n",
    "\n",
    "'''Mask Training'''\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(f'Starting epoch {e}...')\n",
    "    \n",
    "    '''Reload weights'''\n",
    "    handler.network.load_save()\n",
    "    handler.refreeze_weights()\n",
    "    \n",
    "    '''Sampling and generating masks.'''\n",
    "    U1 = torch.rand(1, requires_grad=False).to(handler.network.device)\n",
    "    U2 = torch.rand(1, requires_grad=False).to(handler.network.device)\n",
    "    \n",
    "    \n",
    "    '''Gumbel Sigmoid & Straight through'''\n",
    "    samples = []\n",
    "    for layer in logits:\n",
    "        samples.append(torch.sigmoid((layer - torch.log(torch.log(U1) / torch.log(U2))) / tau))\n",
    "        \n",
    "    binaries_stop = []\n",
    "        \n",
    "    for layer in samples:\n",
    "        with torch.no_grad():\n",
    "            binaries_stop.append((layer > 0.5).float() - layer)\n",
    "        \n",
    "    binaries = []\n",
    "    iterator_samples = iter(samples)\n",
    "          \n",
    "    for idx, layer in enumerate(binaries_stop):\n",
    "        binaries.append(layer + next(iterator_samples))\n",
    "    bin_iter = iter(binaries)\n",
    "\n",
    "        \n",
    "#     # iterator_binaries = iter(binaries)\n",
    "#     bin_iter = iter(binaries)\n",
    "#     idx = 0\n",
    "#     for layer in handler.network.layers[0]:\n",
    "#         if isinstance(layer, torch.nn.Linear):\n",
    "#             layer.weight.data =  layer.weight.data * next(bin_iter).data\n",
    "#             idx += 1\n",
    "    \n",
    "    '''Inference with masked network and backpropagation.'''\n",
    "    batch = next(iterator_train)\n",
    "    # Load in batch data (not binaries for one-hot input)\n",
    "    inp = torch.stack([torch.stack([b[0], b[1]]) for b in batch])\n",
    "    otp = torch.stack([b[2] for b in batch])\n",
    "    ops = torch.stack([b[3] for b in batch])\n",
    "    # Convert batch data toone-hot representation\n",
    "    inp, otp_ = handler.set_batched_digits(inp, otp, ops)\n",
    "    inp_ = inp.to(handler.network.device)\n",
    "    otp_ = otp_.to(handler.network.device)\n",
    "    \n",
    "    '''Pass batch data through masked net'''\n",
    "    idx = 0\n",
    "    for layer in handler.network.layers[0]:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            b = layer.bias\n",
    "            w = layer.weight.detach()\n",
    "            m = next(bin_iter)\n",
    "            inp_ = handler.network.forward_mask_layer(inp_, m, w, b)\n",
    "            idx+=1\n",
    "        else:\n",
    "            inp_ = layer(inp_)\n",
    "    otp_pred = inp_       \n",
    "    \n",
    "    '''Fetch Running Accuracy'''\n",
    "    with torch.no_grad():\n",
    "        diff = otp_pred.view(-1).detach() - otp_.view(-1).detach()\n",
    "        cnt = len(diff[abs(diff)<0.1])\n",
    "        print(f'Accuracy: {cnt/(len(diff))} ')\n",
    "    \n",
    "    assert otp_pred.is_leaf == False\n",
    "    \n",
    "    all_logits = alpha*torch.cat([layer.view(-1).detach() for layer in logits]).to(handler.network.device)\n",
    "    optimiser.zero_grad()\n",
    "    loss = criterion(otp_pred, otp_).to(handler.network.device) + torch.sum(all_logits).detach()\n",
    "    loss.backward()\n",
    "    \n",
    "    for layer in handler.network.layers[0]:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            assert layer.weight.grad == None\n",
    "    optimiser.step()\n",
    "    \n",
    "            \n",
    "    loss_hist.append(loss.item())\n",
    "    avg.append(np.mean(loss_hist[-100:]))\n",
    "    if e % 100 == 0:\n",
    "        print(logits[0])\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        #plt.plot(loss_hist)\n",
    "        plt.plot(avg)\n",
    "        plt.savefig('liveplot.png')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    if e % 100 == 0:\n",
    "        print('Saving Mask...')\n",
    "        torch.save(logits, 'masks/trained_logits_add_mask_.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5b9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7ea12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
