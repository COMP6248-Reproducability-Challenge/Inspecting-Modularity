{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0788e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.addmul import HandleAddMul\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b79c3793",
   "metadata": {},
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a4f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_cache_dir = \"networks/cache-networks/\"\n",
    "network_name = \"lyr256-split0.8-lr0.01-mul.data\"\n",
    "\n",
    "checkpoint = True\n",
    "test_flag = 1\n",
    "\n",
    "input_dims = [42]\n",
    "output_dims = [20]\n",
    "batchsize = 128\n",
    "num_epochs = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225b7427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-mul.data\n",
      "Load saves ...\n"
     ]
    }
   ],
   "source": [
    "handler = HandleAddMul(input_dims, output_dims, dir=network_cache_dir+network_name, checkpoint=checkpoint, lr=0.001)\n",
    "\n",
    "for param in handler.network.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7faf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 42])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([20, 2000])\n"
     ]
    }
   ],
   "source": [
    "weights = [layer.weight.data for layer in handler.network.layers[0] if isinstance(layer, torch.nn.Linear)]\n",
    "for layer in weights: print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "\n",
    "for weight in weights:\n",
    "    logits.append(torch.full_like(weight, 0.9)) # initialise logit tensors with 0.9, corresponding shapes as weights\n",
    "\n",
    "for layer in logits: print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "\n",
    "data_fp = \"generate_datasets/tmp/digit-data/simple_add.npy\"\n",
    "data = np.load(data_fp, allow_pickle=True)\n",
    "\n",
    "data_len = len(data)\n",
    "train_split_idx = int(data_len * train_split)\n",
    "train_data = data[:train_split_idx]\n",
    "test_data = data[train_split_idx:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.tensor(train_data), batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.Tensor(test_data), batch_size=batchsize, shuffle=True)\n",
    "\n",
    "iterator_train = iter(train_loader)\n",
    "iterator_test = iter(test_loader)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(logits, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6539bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100 # NB: check for number of training epochs in paper\n",
    "tau = 1 # temperature parameter, NB: check for value in paper\n",
    "alpha = 1 # regularisation parameter, NB: check for value in paper\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(f'Starting epoch {e}...')\n",
    "\n",
    "    '''Sampling and generating masks.'''\n",
    "\n",
    "    U1 = torch.rand(1).to(handler.network.device)\n",
    "    U2 = torch.rand(1).to(handler.network.device)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for layer in logits:\n",
    "        layer.requires_grad_(requires_grad=True)\n",
    "\n",
    "        '''\n",
    "        if layer.grad is not None:\n",
    "            layer.grad.detach_()\n",
    "            layer.grad.zero_()\n",
    "        '''\n",
    "\n",
    "        samples.append(torch.sigmoid((layer - torch.log(torch.log(U1) / torch.log(U2))) / tau))\n",
    "\n",
    "    binaries_stop = []\n",
    "\n",
    "    for layer in samples:\n",
    "        with torch.no_grad():\n",
    "            binaries_stop.append((layer > 0.5).float() - layer)\n",
    "\n",
    "    binaries = []\n",
    "    iterator_samples = iter(samples)\n",
    "\n",
    "    for layer in binaries_stop:\n",
    "        binaries.append(layer + next(iterator_samples))\n",
    "\n",
    "    iterator_binaries = iter(binaries)\n",
    "\n",
    "    for layer in handler.network.layers[0]:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            layer.weight.data * next(iterator_binaries)\n",
    "\n",
    "    '''Inference with masked network and backpropagation.'''\n",
    "\n",
    "    batch = next(iterator_train)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inp = [[b[0].item(), b[1].item()] for b in batch]\n",
    "\n",
    "        otp = [int(b[2].item()) for b in batch]\n",
    "        ops = [b[3].item() for b in batch]\n",
    "        inp, otp_ = handler.set_batched_digits(inp, otp, ops)\n",
    "\n",
    "        inp_ = torch.Tensor(np.array(inp)).to(handler.network.device)\n",
    "\n",
    "        otp_pred = handler.network.forward(inp_)\n",
    "        pred = []\n",
    "        for o in otp_pred:\n",
    "            x = [i%10 for i, t in enumerate(o) if t > 0.7]\n",
    "            if len(x) == 2: # so if we determine a 2-digit number\n",
    "                val_ = x[0]*10 + x[1]\n",
    "                pred.append(val_)\n",
    "            else:\n",
    "                pred.append(100)\n",
    "\n",
    "    otp = torch.Tensor(np.array(otp)).to(handler.network.device)\n",
    "    pred = torch.tensor(np.array(pred)).to(handler.network.device)\n",
    "\n",
    "    all_logits = torch.cat([layer.view(-1) for layer in logits])\n",
    "    loss = criterion(pred, otp) + alpha * sum(all_logits)\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f290478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE FROM PAPER: Typically multiple (between 4–8) binary masks\n",
    "# are sampled and applied to different parts of a batch to improve the quality of the estimated gradient.\n",
    "\n",
    "# ANOTHER NOTE: This is achieved by adding a regularization term [SEE PAPER FOR EQUATION]\n",
    "# where α ∈ [0, ∞) is a hyper-parameter responsible for the strength of the regularization.\n",
    "# How to best choose α is described in detail in Appendix C.3."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b16c64fa",
   "metadata": {},
   "source": [
    "### EXAMPLE CODE FOR ABOVE CELL ###\n",
    "\n",
    "# This is our starting vector\n",
    "initial=[[2.0], [1.0], [10.0]]\n",
    "\n",
    "# This is the function we will optimise (feel free to work out the analytic minima!)\n",
    "def function(x):\n",
    "    return x[0]**2 + x[1]**2 + x[2]**2\n",
    "\n",
    "x = torch.tensor(initial, requires_grad=True, dtype=torch.float)\n",
    "for i in range(0,100):\n",
    "    # manually dispose of the gradient (in reality it would be better to detach and zero it to reuse memory)\n",
    "    x.grad=None\n",
    "    # evaluate the function\n",
    "    J = function(x) \n",
    "    # auto-compute the gradients at the previously evaluated point x\n",
    "    J.backward()\n",
    "    # compute the update\n",
    "    x.data = x - x.grad*0.1 \n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print((x, function(x).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of the training process, deterministic binary masks M_i \\in {0, 1}\n",
    "# for weights i are obtained via thresholding M_i = [\\mathbb{1}]σ(li)>0.5^2.\n",
    "# Applying the full mask M then uncovers the module responsible for the target task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
