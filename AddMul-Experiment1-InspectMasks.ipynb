{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0788e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.addmul import HandleAddMul"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96b29cec",
   "metadata": {},
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a4f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-mul.data\n",
      "Load saves ...\n"
     ]
    }
   ],
   "source": [
    "network_cache_dir = \"networks/cache-networks/\"\n",
    "network_name = \"lyr256-split0.8-lr0.01-add-mul.data\"\n",
    "\n",
    "checkpoint = True\n",
    "test_flag = 1\n",
    "\n",
    "input_dims = [42]\n",
    "output_dims = [20]\n",
    "batchsize = 128\n",
    "num_epochs = 1\n",
    "\n",
    "handler = HandleAddMul(input_dims, output_dims, dir=network_cache_dir + network_name, checkpoint=checkpoint, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cc85a",
   "metadata": {},
   "source": [
    "# Test the Add mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225b7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Parameters in Network\n",
    "for name, param in handler.network.named_parameters():\n",
    "    param.requires_grad = False\n",
    "# Fetch Mask\n",
    "load_logits = torch.load('trained_logits.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbaf9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "test_split = 1 - train_split\n",
    "\n",
    "data_fp = \"generate_datasets/tmp/digit-data/simple_mul.npy\"\n",
    "data = np.load(data_fp, allow_pickle=True)\n",
    "\n",
    "data_len = len(data)\n",
    "train_split_idx = int(data_len * train_split)\n",
    "train_data = data[:train_split_idx]\n",
    "test_data = data[train_split_idx:]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=torch.tensor(train_data), batch_size=batchsize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=torch.Tensor(test_data), batch_size=batchsize, shuffle=True)\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "iterator_train = iter(cycle(train_loader))\n",
    "iterator_test = iter(cycle(test_loader))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimiser = torch.optim.Adam(logits, lr=0.01)\n",
    "\n",
    "NUM_EPOCHS = 20000  # NB: check for number of training epochs in paper\n",
    "tau = 1  # temperature parameter, NB: check for value in paper\n",
    "alpha = 0.0001/128  # regularisation parameter, NB: check for value in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f25cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0...\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "NUM_EPOCHS = 1\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print(f'Starting epoch {e}...')\n",
    "\n",
    "    '''Sampling and generating masks.'''\n",
    "\n",
    "    U1 = torch.rand(1, requires_grad=True).to(handler.network.device)\n",
    "    U2 = torch.rand(1, requires_grad=True).to(handler.network.device)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for layer in logits:\n",
    "        layer.requires_grad_(requires_grad=True)\n",
    "\n",
    "        #         if layer.grad is not None:\n",
    "        #             layer.grad.detach_()\n",
    "        #             layer.grad.zero_()\n",
    "\n",
    "        samples.append(torch.sigmoid((layer - torch.log(torch.log(U1) / torch.log(U2))) / tau))\n",
    "\n",
    "    binaries_stop = []\n",
    "\n",
    "    for layer in samples:\n",
    "        with torch.no_grad():\n",
    "            binaries_stop.append((layer > 0.5).float() - layer)\n",
    "\n",
    "    binaries = []\n",
    "    iterator_samples = iter(samples)\n",
    "\n",
    "    for layer in binaries_stop:\n",
    "        binaries.append(layer + next(iterator_samples))\n",
    "\n",
    "    iterator_binaries = iter(binaries)\n",
    "\n",
    "    for layer in handler.network.layers[0]:\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            layer.weight.data * next(iterator_binaries)\n",
    "\n",
    "    '''Inference with masked network and backpropagation.'''\n",
    "\n",
    "    batch = next(iterator_train)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Load in batch data (not binaries for one-hot input)\n",
    "        inp = torch.stack([torch.stack([b[0], b[1]]) for b in batch])\n",
    "        otp = torch.stack([b[2] for b in batch])\n",
    "        ops = torch.stack([b[3] for b in batch])\n",
    "        # Convert batch data toone-hot representation\n",
    "        inp, otp_ = handler.set_batched_digits(inp, otp, ops)\n",
    "        \n",
    "        inp_ = inp.to(handler.network.device)\n",
    "        otp_ = otp_.to(handler.network.device)\n",
    "        \n",
    "        otp_pred = handler.network(inp_)\n",
    "\n",
    "        \n",
    "    all_logits = alpha*torch.cat([layer.view(-1) for layer in logits]).to(handler.network.device)\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    loss = criterion(otp_pred, otp_).to(handler.network.device) + torch.sum(all_logits)\n",
    "    #loss.requires_grad = True\n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    loss_hist.append(loss.item())\n",
    "    \n",
    "    if e % 200 == 0:\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.plot(loss_hist)\n",
    "        plt.savefig('liveplot.png')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        torch.save(logits, 'trainbd_logits.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6806c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing withuot Mask 0...\n",
      "0.9928571428571429\n",
      "Starting testing withuot Mask 1...\n",
      "0.94609375\n",
      "Starting testing withuot Mask 2...\n",
      "0.9428571428571428\n",
      "Starting testing withuot Mask 3...\n",
      "0.948828125\n",
      "Starting testing withuot Mask 4...\n",
      "0.8928571428571429\n",
      "Starting testing withuot Mask 5...\n",
      "0.94375\n",
      "Starting testing withuot Mask 6...\n",
      "0.9857142857142858\n",
      "Starting testing withuot Mask 7...\n",
      "0.945703125\n",
      "Starting testing withuot Mask 8...\n",
      "0.95\n",
      "Starting testing withuot Mask 9...\n",
      "0.94296875\n",
      "Starting testing withuot Mask 10...\n",
      "1.0\n",
      "Starting testing withuot Mask 11...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 12...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 13...\n",
      "0.94453125\n",
      "Starting testing withuot Mask 14...\n",
      "0.9714285714285714\n",
      "Starting testing withuot Mask 15...\n",
      "0.946484375\n",
      "Starting testing withuot Mask 16...\n",
      "0.9357142857142857\n",
      "Starting testing withuot Mask 17...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 18...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 19...\n",
      "0.946875\n",
      "Starting testing withuot Mask 20...\n",
      "0.9285714285714286\n",
      "Starting testing withuot Mask 21...\n",
      "0.94375\n",
      "Starting testing withuot Mask 22...\n",
      "0.9857142857142858\n",
      "Starting testing withuot Mask 23...\n",
      "0.9484375\n",
      "Starting testing withuot Mask 24...\n",
      "0.9\n",
      "Starting testing withuot Mask 25...\n",
      "0.94609375\n",
      "Starting testing withuot Mask 26...\n",
      "0.9428571428571428\n",
      "Starting testing withuot Mask 27...\n",
      "0.94609375\n",
      "Starting testing withuot Mask 28...\n",
      "0.9428571428571428\n",
      "Starting testing withuot Mask 29...\n",
      "0.943359375\n",
      "Starting testing withuot Mask 30...\n",
      "0.9928571428571429\n",
      "Starting testing withuot Mask 31...\n",
      "0.9484375\n",
      "Starting testing withuot Mask 32...\n",
      "0.9\n",
      "Starting testing withuot Mask 33...\n",
      "0.943359375\n",
      "Starting testing withuot Mask 34...\n",
      "0.9928571428571429\n",
      "Starting testing withuot Mask 35...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 36...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 37...\n",
      "0.948046875\n",
      "Starting testing withuot Mask 38...\n",
      "0.9071428571428571\n",
      "Starting testing withuot Mask 39...\n",
      "0.946875\n",
      "Starting testing withuot Mask 40...\n",
      "0.9285714285714286\n",
      "Starting testing withuot Mask 41...\n",
      "0.948828125\n",
      "Starting testing withuot Mask 42...\n",
      "0.8928571428571429\n",
      "Starting testing withuot Mask 43...\n",
      "0.94921875\n",
      "Starting testing withuot Mask 44...\n",
      "0.8857142857142857\n",
      "Starting testing withuot Mask 45...\n",
      "0.9515625\n",
      "Starting testing withuot Mask 46...\n",
      "0.8428571428571429\n",
      "Starting testing withuot Mask 47...\n",
      "0.9484375\n",
      "Starting testing withuot Mask 48...\n",
      "0.9\n",
      "Starting testing withuot Mask 49...\n",
      "0.946484375\n",
      "Starting testing withuot Mask 50...\n",
      "0.9357142857142857\n",
      "Starting testing withuot Mask 51...\n",
      "0.94765625\n",
      "Starting testing withuot Mask 52...\n",
      "0.9142857142857143\n",
      "Starting testing withuot Mask 53...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 54...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 55...\n",
      "0.94375\n",
      "Starting testing withuot Mask 56...\n",
      "0.9857142857142858\n",
      "Starting testing withuot Mask 57...\n",
      "0.946484375\n",
      "Starting testing withuot Mask 58...\n",
      "0.9357142857142857\n",
      "Starting testing withuot Mask 59...\n",
      "0.948046875\n",
      "Starting testing withuot Mask 60...\n",
      "0.9071428571428571\n",
      "Starting testing withuot Mask 61...\n",
      "0.945703125\n",
      "Starting testing withuot Mask 62...\n",
      "0.95\n",
      "Starting testing withuot Mask 63...\n",
      "0.94453125\n",
      "Starting testing withuot Mask 64...\n",
      "0.9714285714285714\n",
      "Starting testing withuot Mask 65...\n",
      "0.944921875\n",
      "Starting testing withuot Mask 66...\n",
      "0.9642857142857143\n",
      "Starting testing withuot Mask 67...\n",
      "0.944921875\n",
      "Starting testing withuot Mask 68...\n",
      "0.9642857142857143\n",
      "Starting testing withuot Mask 69...\n",
      "0.94765625\n",
      "Starting testing withuot Mask 70...\n",
      "0.9142857142857143\n",
      "Starting testing withuot Mask 71...\n",
      "0.94296875\n",
      "Starting testing withuot Mask 72...\n",
      "1.0\n",
      "Starting testing withuot Mask 73...\n",
      "0.9484375\n",
      "Starting testing withuot Mask 74...\n",
      "0.9\n",
      "Starting testing withuot Mask 75...\n",
      "0.94609375\n",
      "Starting testing withuot Mask 76...\n",
      "0.9428571428571428\n",
      "Starting testing withuot Mask 77...\n",
      "0.943359375\n",
      "Starting testing withuot Mask 78...\n",
      "0.9928571428571429\n",
      "Starting testing withuot Mask 79...\n",
      "0.94609375\n",
      "Starting testing withuot Mask 80...\n",
      "0.9428571428571428\n",
      "Starting testing withuot Mask 81...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 82...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 83...\n",
      "0.94453125\n",
      "Starting testing withuot Mask 84...\n",
      "0.9714285714285714\n",
      "Starting testing withuot Mask 85...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 86...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 87...\n",
      "0.944921875\n",
      "Starting testing withuot Mask 88...\n",
      "0.9642857142857143\n",
      "Starting testing withuot Mask 89...\n",
      "0.9453125\n",
      "Starting testing withuot Mask 90...\n",
      "0.9571428571428572\n",
      "Starting testing withuot Mask 91...\n",
      "0.94375\n",
      "Starting testing withuot Mask 92...\n",
      "0.9857142857142858\n",
      "Starting testing withuot Mask 93...\n",
      "0.9484375\n",
      "Starting testing withuot Mask 94...\n",
      "0.9\n",
      "Starting testing withuot Mask 95...\n",
      "0.946484375\n",
      "Starting testing withuot Mask 96...\n",
      "0.9357142857142857\n",
      "Starting testing withuot Mask 97...\n",
      "0.94375\n",
      "Starting testing withuot Mask 98...\n",
      "0.9857142857142858\n",
      "Starting testing withuot Mask 99...\n",
      "0.943359375\n",
      "0.9457583705357138\n"
     ]
    }
   ],
   "source": [
    "NUM_TEST_EPOCHS =100\n",
    "\n",
    "cumsum_accurary = 0 \n",
    "for e in range(NUM_TEST_EPOCHS):\n",
    "    print(f'Starting testing withuot Mask {e}...')\n",
    "\n",
    "    '''Inference with masked network and backpropagation.'''\n",
    "\n",
    "    batch = next(iterator_test)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Load in batch data (not binaries for one-hot input)\n",
    "        inp = torch.stack([torch.stack([b[0], b[1]]) for b in batch])\n",
    "        otp = torch.stack([b[2] for b in batch])\n",
    "        ops = torch.stack([b[3] for b in batch])\n",
    "        # Convert batch data toone-hot representation\n",
    "        inp, otp_ = handler.set_batched_digits(inp, otp, ops)\n",
    "        \n",
    "        inp_ = inp.to(handler.network.device)\n",
    "        otp_target = otp_.to(handler.network.device)\n",
    "        \n",
    "        otp_pred = handler.network(inp_)\n",
    "        \n",
    "        diff = otp_target - otp_pred\n",
    "        running_acc = len(diff[diff<0.005])/(diff.size()[0]*20)\n",
    "        print(running_acc)\n",
    "        cumsum_accurary += running_acc\n",
    "print(cumsum_accurary/NUM_TEST_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9ed079",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sig_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m load_logits:\n\u001b[1;32m---> 10\u001b[0m     \u001b[43msig_logits\u001b[49m\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39msigmoid((layer \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mlog(U1) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(U2))) \u001b[38;5;241m/\u001b[39m tau))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#     sig_logits.append(torch.sigmoid(layer))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m binary_sample \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sig_logits' is not defined"
     ]
    }
   ],
   "source": [
    "load_logits = torch.load('trained_logits.pt')\n",
    "\n",
    "U1 = torch.rand(1, requires_grad=True).to(handler.network.device)\n",
    "U2 = torch.rand(1, requires_grad=True).to(handler.network.device)\n",
    "\n",
    "\n",
    "# Sigmoid(l_i) rather than sigmoid(T(li-log(logU1/logU2)))\n",
    "samples = []\n",
    "for layer in load_logits:\n",
    "    sig_logits.append(torch.sigmoid((layer - torch.log(torch.log(U1) / torch.log(U2))) / tau))\n",
    "#     sig_logits.append(torch.sigmoid(layer))\n",
    "\n",
    "binary_sample = []\n",
    "for layer in samples:\n",
    "    binary_sample.append((layer > 0.5).float() - layer )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
