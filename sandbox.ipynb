{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0788e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.addmul import HandleAddMul\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "37a4f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_cache_dir = \"networks/cache-networks/\"\n",
    "network_name = \"lyr256-split0.8-lr0.01-mul.data\"\n",
    "\n",
    "checkpoint = True\n",
    "test_flag = 1\n",
    "\n",
    "input_dims = [42]\n",
    "output_dims = [20]\n",
    "batchsize = 128\n",
    "num_epochs = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "225b7427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... FNN Network training on cuda:0 ...\n",
      "Accessing : networks/cache-networks/lyr256-split0.8-lr0.01-mul.data\n",
      "networks/cache-networks/lyr256-split0.8-lr0.01-mul.data\n",
      "Load saves ...\n"
     ]
    }
   ],
   "source": [
    "handler = HandleAddMul(input_dims, output_dims, dir=network_cache_dir+network_name, checkpoint=checkpoint, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7020bb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 42])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([20, 2000])\n"
     ]
    }
   ],
   "source": [
    "weights = [layer.weight.data for layer in handler.network.layers[0] if isinstance(layer, torch.nn.Linear)]\n",
    "for weight in weights: print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dbaf9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 42])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([2000, 2000])\n",
      "torch.Size([20, 2000])\n"
     ]
    }
   ],
   "source": [
    "logits = []\n",
    "\n",
    "for weight in weights:\n",
    "    logits.append(torch.full_like(weight, 0.9)) # initialise logit tensors with 0.9, corresponding shapes as weights\n",
    "\n",
    "for logit in logits: print(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d72352ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20124000])\n"
     ]
    }
   ],
   "source": [
    "flattened_logits = [torch.flatten(logit) for logit in logits]\n",
    "flattened_logits = torch.cat(flattened_logits, 0)\n",
    "print(flattened_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "223e2493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: tensor([20136020.])\n",
      "Number of biases: tensor([12020.])\n",
      "Hence number of weights: tensor([20124000.])\n"
     ]
    }
   ],
   "source": [
    "# verify that the number of logits/weights is correct\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, handler.network.parameters())\n",
    "params = torch.Tensor([sum([torch.prod(torch.Tensor(list(p.size()))) for p in model_parameters])])\n",
    "print(f'Number of params: {params}')\n",
    "\n",
    "biases = [layer.bias.data for layer in handler.network.layers[0] if isinstance(layer, torch.nn.Linear)]\n",
    "num_biases = sum([torch.Tensor(list(bias.size())) for bias in biases])\n",
    "print(f'Number of biases: {num_biases}')\n",
    "print(f'Hence number of weights: {params - num_biases}')\n",
    "\n",
    "assert(torch.Tensor(list(flattened_logits.shape)) == (params - num_biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain a sample from each logit for the corresponding mask\n",
    "# by broadcasting Equation (1) on the logit tensor to obtain a sample tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4bd26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarise the sample tensor using Equation (2) to obtain the actual mask tensor\n",
    "# each value is either 0 or 1, based on the thresholding function\n",
    "# note that the optimiser only backpropagates through s_i -- be careful with function specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a31ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise multiplication between mask tensor and trained model weights\n",
    "# to obtain masked weights\n",
    "\n",
    "# model.parameters\n",
    "# perhaps in-place operation possible for masking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f290478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inference using model defined with *masked weights*\n",
    "# evaluate loss\n",
    "# backpropagate loss into logits (loss.backward, logits.grad)\n",
    "# update logits, presumably using update equation\n",
    "\n",
    "# NOTE FROM PAPER: Typically multiple (between 4–8) binary masks\n",
    "# are sampled and applied to different parts of a batch to improve the quality of the estimated gradient.\n",
    "\n",
    "# ANOTHER NOTE: This is achieved by adding a regularization term [SEE PAPER FOR EQUATION]\n",
    "# where α ∈ [0, ∞) is a hyper-parameter responsible for the strength of the regularization.\n",
    "# How to best choose α is described in detail in Appendix C.3."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b16c64fa",
   "metadata": {},
   "source": [
    "### EXAMPLE CODE FOR ABOVE CELL ###\n",
    "\n",
    "# This is our starting vector\n",
    "initial=[[2.0], [1.0], [10.0]]\n",
    "\n",
    "# This is the function we will optimise (feel free to work out the analytic minima!)\n",
    "def function(x):\n",
    "    return x[0]**2 + x[1]**2 + x[2]**2\n",
    "\n",
    "x = torch.tensor(initial, requires_grad=True, dtype=torch.float)\n",
    "for i in range(0,100):\n",
    "    # manually dispose of the gradient (in reality it would be better to detach and zero it to reuse memory)\n",
    "    x.grad=None\n",
    "    # evaluate the function\n",
    "    J = function(x) \n",
    "    # auto-compute the gradients at the previously evaluated point x\n",
    "    J.backward()\n",
    "    # compute the update\n",
    "    x.data = x - x.grad*0.1 \n",
    "    \n",
    "    if i%10 == 0:\n",
    "        print((x, function(x).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end of the training process, deterministic binary masks M_i \\in {0, 1}\n",
    "# for weights i are obtained via thresholding M_i = [\\mathbb{1}]σ(li)>0.5^2.\n",
    "# Applying the full mask M then uncovers the module responsible for the target task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
